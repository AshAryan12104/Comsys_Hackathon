
# ğŸ¯ Robust Face and Gender Recognition in Challenging Environments

This repository contains our complete solution for the **Comsys Hackathon**, where we address two real-world computer vision tasks using PyTorch, metric learning, and a web-based evaluation frontend.

---

## ğŸ§  Tasks Overview

### ğŸ”¹ Task A â€“ Gender Classification
- **Objective**: Classify face images as **male** or **female**
- **Model**: ResNet18 backbone + binary classification head
- **Evaluation**: Accuracy, Precision, Recall, F1-score

### ğŸ”¹ Task B â€“ Face Recognition (Matching)
- **Objective**: Match distorted face images to correct identities
- **Model**: Triplet-based embedding model using **FaceNet** (InceptionResnetV1)
- **Evaluation**: Top-1 Accuracy, Macro-averaged F1-score

---

## ğŸ“ Project Structure

<pre> ```
Comsys_Hackathon/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Task_A/...
â”‚   â””â”€â”€ Task_B/...
â”‚
â”‚
â”œâ”€â”€ backend.py
â”œâ”€â”€ config.yaml
â”œâ”€â”€ evaluate_task_a.py
â”œâ”€â”€ evaluate_matcher_results.py
â”œâ”€â”€ matcher.py
â”œâ”€â”€ train.py
â”œâ”€â”€ train_matcher.py
â”œâ”€â”€ evaluate.py
â”œâ”€â”€ main.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”œâ”€â”€ helpers.py
â”‚   â””â”€â”€ triplet_dataset.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ multitask_model.py
â”‚   â””â”€â”€ embedding_model.py
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â”œâ”€â”€ best_model.pt     # For Task A
â”‚   â”‚   â””â”€â”€ matcher_model.pt  # For Task B
â”‚   â”‚
â”‚   â””â”€â”€ results/
â”‚       â”œâ”€â”€ face_recognition_results.csv
â”‚       â””â”€â”€ matcher_progress.txt
â”‚
â”œâ”€â”€ index.html
â”‚
â”œâ”€â”€ style.css
â”‚
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ test_path.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ training_result.md
â””â”€â”€ summary/
    â””â”€â”€ Comsys_Hackathon.pdf
``` </pre>

---

## ğŸ§  Architecture

### Task A â€“ Gender Classification
â€¢	Backbone: ResNet18 (pretrained on ImageNet)
â€¢	Final FC layer replaced with a 1-node Sigmoid output head
â€¢	Only gender head used (no multitask mode)

        Input (224x224x3)
                â†“
        ResNet18 Backbone
                â†“
        Fully Connected Layer (1)
                â†“
            Sigmoid â†’ Binary Gender Output

### Task B â€“ Face Recognition (Matching)
â€¢	Backbone: FaceNet (InceptionResNetV1) from facenet-pytorch
â€¢	Embedding size: 512-D vector
â€¢	Matching Logic:
        o	Reference embedding per identity from 1 clean image
        o	Compare distorted test images using cosine similarity
        o	Apply identity threshold (0.65) to validate match

        Test Image   â†’ EmbeddingModel (FaceNet) â†’ 512D Embedding
        Reference    â†’ EmbeddingModel (FaceNet) â†’ 512D Embedding
                        â†“
                Cosine Similarity
                        â†“
                Best Match + Threshold
                        â†“
                Match (Label = 1 or 0)

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repo
<pre> ```
git clone https://github.com/AshAryan12104/Comsys_Hackathon
cd Comsys_Hackathon
``` </pre>

### 2. Install Dependencies
<pre>
pip install -r requirements.txt
</pre>

### 3. Train Models

#### ğŸ”¹ Task A (Gender Classification)
<pre>
python main.py --mode train --config config.yaml
</pre>

#### ğŸ”¹ Task B (Face Matching)
<pre>
python train_matcher.py
</pre>

---

## ğŸ” Download Pretrained Model Weights

To run evaluation without retraining, download the pretrained model checkpoints from the link below:

ğŸ“¦ [Download Model Weights from Google Drive](https://drive.google.com/drive/folders/1IjbLg77rXdhvyadaN2vDwgEpFyu935v2?usp=sharing)

### Files Included:

- `best_model.pt` â†’ Used for Task A (Gender Classification)
- `matcher_model.pt` â†’ Used for Task B (Face Matching)

### ğŸ“‚ Where to Place the Files:

After downloading, place them in the following location inside the project: (This is very important)
<pre> ```
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â”œâ”€â”€ best_model.pt     # For Task A
â”‚   â”‚   â””â”€â”€ matcher_model.pt  # For Task B
``` </pre>

> âš ï¸ Make sure the folder structure matches exactly, or the evaluation scripts may not find the model files.

---

## âœ… Evaluation

### ğŸ”¹ Task A (Gender)
<pre>
python evaluate_task_a.py --val_dir path/to/your/val/folder 
</pre>

**Example :**
<pre>
python evaluate_task_a.py --val_dir data/Task_A/val 
</pre>

### ğŸ”¹ Task B (Face Recognition)
<pre>
python matcher.py --test_dir path/to/your/val/folder
</pre>
After complete running matcher.py, Run
<pre>
python evaluate_matcher_results.py
</pre>

**Example :**
<pre>
python matcher.py --test_dir data/Task_B/val
</pre>
<pre>
python evaluate_matcher_results.py
</pre>

---

## ğŸŒ Frontend: Web Evaluation Portal 

1. Run the backend:
<pre>
python backend.py
</pre>

2. Open your browser and visit :
http://localhost:5000

3. Enter validation folder path (e.g. data/Task_A/val)

4. Click **Evaluate Task A** or **Evaluate Task B**

5. A progress bar appears for Task B and shows % as matcher.py runs in real-time.

6. On invalid path or wrong structure, error message is now shown on the webpage.

7. View metrics on screen after evaluation of respective Task !!!

> â³ If the server restarts or glitches on first try, just click the button again after refresh.

---

## ğŸ“Š Sample Metrics

### âœ… Task A
- Accuracy: 94.79%
- Precision: 97.43%
- Recall: 95.58%
- F1-Score: 96.50%

### âœ… Task B
- Top-1 Accuracy: 100.00%
- Macro-Averaged F1-Score: 100.00%

> Training And Validation Results are on training_result.md

---

## ğŸ“„ License

This project is developed as part of a Hackathon and is intended for academic and demonstration use only.

---

## ğŸ‘¥ Team BYTEBash

- **Name:** Md Aryan Rehman, Raiyan Aftab Ansari, Priyanshu Mishra.
- **GitHub:** https://github.com/AshAryan12104
- **Email:** aryanrehman12104@gmail.com
---
